name: Deploy Dashboard to AWS

on:
  push:
    branches: [main]
    paths:
      - 'dashboard/**'
      - '.github/workflows/deploy-dashboard.yml'
  workflow_dispatch: # Allow manual trigger from GitHub UI

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: vibe-dashboard
  ECS_CLUSTER: vibe-cluster
  ECS_SERVICE: vibe-dashboard
  CONTAINER_NAME: vibe-dashboard

jobs:
  deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repository if not exists
        run: |
          aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} 2>/dev/null || \
          aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd dashboard
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Setup Infrastructure (VPC, ALB, Target Group)
        id: infra
        run: |
          # Get VPC
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=vibe-vpc" --query 'Vpcs[0].VpcId' --output text)
          if [ "$VPC_ID" == "None" ] || [ -z "$VPC_ID" ]; then
            VPC_ID=$(aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --query 'Vpcs[0].VpcId' --output text)
          fi
          echo "vpc_id=$VPC_ID" >> $GITHUB_OUTPUT

          # Get subnets (need at least 2 in different AZs for ALB)
          SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[*].SubnetId' --output text | tr '\t' ',')
          echo "subnet_ids=$SUBNET_IDS" >> $GITHUB_OUTPUT

          # Create or get ALB security group
          ALB_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-alb-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          if [ "$ALB_SG_ID" == "None" ] || [ -z "$ALB_SG_ID" ]; then
            ALB_SG_ID=$(aws ec2 create-security-group --group-name vibe-dashboard-alb-sg --description "Vibe Dashboard ALB Security Group" --vpc-id $VPC_ID --query 'GroupId' --output text)
            aws ec2 authorize-security-group-ingress --group-id $ALB_SG_ID --protocol tcp --port 80 --cidr 0.0.0.0/0
            aws ec2 authorize-security-group-ingress --group-id $ALB_SG_ID --protocol tcp --port 443 --cidr 0.0.0.0/0
          fi
          echo "alb_sg_id=$ALB_SG_ID" >> $GITHUB_OUTPUT

          # Create or get ECS task security group
          ECS_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-ecs-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          if [ "$ECS_SG_ID" == "None" ] || [ -z "$ECS_SG_ID" ]; then
            ECS_SG_ID=$(aws ec2 create-security-group --group-name vibe-dashboard-ecs-sg --description "Vibe Dashboard ECS Security Group" --vpc-id $VPC_ID --query 'GroupId' --output text)
            # Allow traffic from ALB only
            aws ec2 authorize-security-group-ingress --group-id $ECS_SG_ID --protocol tcp --port 3001 --source-group $ALB_SG_ID
          fi
          echo "ecs_sg_id=$ECS_SG_ID" >> $GITHUB_OUTPUT

          # Create or get ALB
          ALB_ARN=$(aws elbv2 describe-load-balancers --names vibe-dashboard-alb --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "None")
          if [ "$ALB_ARN" == "None" ] || [ -z "$ALB_ARN" ]; then
            # Convert comma-separated to space-separated for ALB creation
            SUBNET_LIST=$(echo $SUBNET_IDS | tr ',' ' ')
            ALB_ARN=$(aws elbv2 create-load-balancer \
              --name vibe-dashboard-alb \
              --subnets $SUBNET_LIST \
              --security-groups $ALB_SG_ID \
              --scheme internet-facing \
              --type application \
              --query 'LoadBalancers[0].LoadBalancerArn' \
              --output text)
            echo "Created new ALB: $ALB_ARN"
          fi
          echo "alb_arn=$ALB_ARN" >> $GITHUB_OUTPUT

          # Get ALB DNS name
          ALB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query 'LoadBalancers[0].DNSName' --output text)
          echo "alb_dns=$ALB_DNS" >> $GITHUB_OUTPUT

          # Create or get target group
          TG_ARN=$(aws elbv2 describe-target-groups --names vibe-dashboard-tg --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "None")
          if [ "$TG_ARN" == "None" ] || [ -z "$TG_ARN" ]; then
            TG_ARN=$(aws elbv2 create-target-group \
              --name vibe-dashboard-tg \
              --protocol HTTP \
              --port 3001 \
              --vpc-id $VPC_ID \
              --target-type ip \
              --health-check-path /api/health \
              --health-check-interval-seconds 30 \
              --healthy-threshold-count 2 \
              --unhealthy-threshold-count 3 \
              --query 'TargetGroups[0].TargetGroupArn' \
              --output text)
            echo "Created new target group: $TG_ARN"
          fi
          echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT

          # Create HTTP listener if not exists
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn $ALB_ARN --query 'Listeners[?Port==`80`].ListenerArn' --output text 2>/dev/null)
          if [ -z "$LISTENER_ARN" ] || [ "$LISTENER_ARN" == "None" ]; then
            aws elbv2 create-listener \
              --load-balancer-arn $ALB_ARN \
              --protocol HTTP \
              --port 80 \
              --default-actions Type=forward,TargetGroupArn=$TG_ARN
            echo "Created HTTP listener"
          fi

      - name: Register new task definition
        id: task-def
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Get AWS account ID
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

          # Create task definition JSON
          cat > task-def.json << EOF
          {
            "family": "vibe-dashboard",
            "networkMode": "awsvpc",
            "requiresCompatibilities": ["FARGATE"],
            "cpu": "512",
            "memory": "1024",
            "executionRoleArn": "arn:aws:iam::${AWS_ACCOUNT_ID}:role/ecsTaskExecutionRole",
            "containerDefinitions": [
              {
                "name": "${{ env.CONTAINER_NAME }}",
                "image": "${ECR_REGISTRY}/${{ env.ECR_REPOSITORY }}:${IMAGE_TAG}",
                "essential": true,
                "portMappings": [
                  {
                    "containerPort": 3001,
                    "protocol": "tcp"
                  }
                ],
                "environment": [
                  {"name": "NODE_ENV", "value": "production"},
                  {"name": "PORT", "value": "3001"}
                ],
                "mountPoints": [
                  {
                    "sourceVolume": "dashboard-data",
                    "containerPath": "/app/data",
                    "readOnly": false
                  }
                ],
                "logConfiguration": {
                  "logDriver": "awslogs",
                  "options": {
                    "awslogs-group": "/ecs/vibe-dashboard",
                    "awslogs-region": "${{ env.AWS_REGION }}",
                    "awslogs-stream-prefix": "ecs",
                    "awslogs-create-group": "true"
                  }
                },
                "healthCheck": {
                  "command": ["CMD-SHELL", "wget -q --spider http://localhost:3001/api/health || exit 1"],
                  "interval": 30,
                  "timeout": 5,
                  "retries": 3,
                  "startPeriod": 60
                }
              }
            ],
            "volumes": [
              {
                "name": "dashboard-data"
              }
            ]
          }
          EOF

          # Register the task definition
          TASK_DEF_ARN=$(aws ecs register-task-definition --cli-input-json file://task-def.json --query 'taskDefinition.taskDefinitionArn' --output text)
          echo "task_def_arn=$TASK_DEF_ARN" >> $GITHUB_OUTPUT

      - name: Delete existing ECS service
        run: |
          # Check if service exists and delete it
          SERVICE_STATUS=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} --query 'services[0].status' --output text 2>/dev/null || echo "MISSING")

          if [ "$SERVICE_STATUS" == "ACTIVE" ]; then
            echo "Deleting existing service..."
            aws ecs delete-service --cluster ${{ env.ECS_CLUSTER }} --service ${{ env.ECS_SERVICE }} --force

            # Wait for service to be fully deleted
            echo "Waiting for service to be deleted..."
            while true; do
              STATUS=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} --query 'services[0].status' --output text 2>/dev/null || echo "MISSING")
              if [ "$STATUS" == "INACTIVE" ] || [ "$STATUS" == "MISSING" ]; then
                echo "Service deleted successfully"
                break
              fi
              echo "Current status: $STATUS - waiting..."
              sleep 10
            done
          else
            echo "No active service found, proceeding with creation"
          fi

      - name: Create ECS service
        run: |
          # Create the ECS service with ALB integration
          aws ecs create-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service-name ${{ env.ECS_SERVICE }} \
            --task-definition ${{ steps.task-def.outputs.task_def_arn }} \
            --desired-count 1 \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[${{ steps.infra.outputs.subnet_ids }}],securityGroups=[${{ steps.infra.outputs.ecs_sg_id }}],assignPublicIp=ENABLED}" \
            --load-balancers "targetGroupArn=${{ steps.infra.outputs.tg_arn }},containerName=${{ env.CONTAINER_NAME }},containerPort=3001" \
            --deployment-configuration "minimumHealthyPercent=0,maximumPercent=200" \
            --health-check-grace-period-seconds 60

      - name: Setup CloudFront Distribution
        id: cloudfront
        run: |
          ALB_DNS="${{ steps.infra.outputs.alb_dns }}"

          # Check if CloudFront distribution exists for this ALB
          EXISTING_DIST=$(aws cloudfront list-distributions --query "DistributionList.Items[?Origins.Items[0].DomainName=='$ALB_DNS'].Id" --output text 2>/dev/null || echo "")

          if [ -n "$EXISTING_DIST" ] && [ "$EXISTING_DIST" != "None" ]; then
            echo "CloudFront distribution already exists: $EXISTING_DIST"
            CF_DOMAIN=$(aws cloudfront get-distribution --id $EXISTING_DIST --query 'Distribution.DomainName' --output text)
            echo "cf_domain=$CF_DOMAIN" >> $GITHUB_OUTPUT
            echo "cf_id=$EXISTING_DIST" >> $GITHUB_OUTPUT
          else
            # Create CloudFront distribution
            CALLER_REF="vibe-dashboard-$(date +%s)"

            cat > cf-config.json << EOF
          {
            "CallerReference": "$CALLER_REF",
            "Comment": "Vibe Dashboard HTTPS",
            "Enabled": true,
            "Origins": {
              "Quantity": 1,
              "Items": [
                {
                  "Id": "alb-origin",
                  "DomainName": "$ALB_DNS",
                  "CustomOriginConfig": {
                    "HTTPPort": 80,
                    "HTTPSPort": 443,
                    "OriginProtocolPolicy": "http-only",
                    "OriginSslProtocols": {
                      "Quantity": 1,
                      "Items": ["TLSv1.2"]
                    }
                  }
                }
              ]
            },
            "DefaultCacheBehavior": {
              "TargetOriginId": "alb-origin",
              "ViewerProtocolPolicy": "redirect-to-https",
              "AllowedMethods": {
                "Quantity": 7,
                "Items": ["GET", "HEAD", "OPTIONS", "PUT", "POST", "PATCH", "DELETE"],
                "CachedMethods": {
                  "Quantity": 2,
                  "Items": ["GET", "HEAD"]
                }
              },
              "ForwardedValues": {
                "QueryString": true,
                "Cookies": {
                  "Forward": "all"
                },
                "Headers": {
                  "Quantity": 3,
                  "Items": ["Authorization", "Origin", "Host"]
                }
              },
              "MinTTL": 0,
              "DefaultTTL": 0,
              "MaxTTL": 0,
              "Compress": true
            },
            "PriceClass": "PriceClass_100",
            "ViewerCertificate": {
              "CloudFrontDefaultCertificate": true
            }
          }
          EOF

            CF_RESULT=$(aws cloudfront create-distribution --distribution-config file://cf-config.json)
            CF_ID=$(echo $CF_RESULT | jq -r '.Distribution.Id')
            CF_DOMAIN=$(echo $CF_RESULT | jq -r '.Distribution.DomainName')

            echo "Created CloudFront distribution: $CF_ID"
            echo "cf_domain=$CF_DOMAIN" >> $GITHUB_OUTPUT
            echo "cf_id=$CF_ID" >> $GITHUB_OUTPUT
          fi

      - name: Wait for service stability
        run: |
          echo "Waiting for service to stabilize..."
          aws ecs wait services-stable --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} || true

      - name: Output URLs
        run: |
          echo ""
          echo "========================================"
          echo "  DEPLOYMENT COMPLETE!"
          echo "========================================"
          echo ""
          echo "  HTTPS URLs (Recommended):"
          echo "  -------------------------"
          echo "  Admin Login:        https://${{ steps.cloudfront.outputs.cf_domain }}/#/login"
          echo "  Participant Portal: https://${{ steps.cloudfront.outputs.cf_domain }}/#/portal"
          echo ""
          echo "  HTTP URLs (Direct ALB - not secure):"
          echo "  ------------------------------------"
          echo "  Admin Login:        http://${{ steps.infra.outputs.alb_dns }}/#/login"
          echo "  Participant Portal: http://${{ steps.infra.outputs.alb_dns }}/#/portal"
          echo ""
          echo "  CloudFront ID: ${{ steps.cloudfront.outputs.cf_id }}"
          echo ""
          echo "  NOTE: CloudFront may take 5-15 minutes to fully deploy."
          echo "        Use the ALB URL initially if CloudFront isn't ready."
          echo ""
          echo "  To add a custom domain later:"
          echo "  1. Request ACM certificate in us-east-1"
          echo "  2. Add domain to CloudFront alternate domain names"
          echo "  3. Create Route 53 alias record pointing to CloudFront"
          echo ""
          echo "========================================"
