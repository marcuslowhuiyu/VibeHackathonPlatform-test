name: Deploy to AWS

on:
  push:
    branches:
      - main
      - dev
      - 'feature/**'
      - 'bugfix/**'
      - 'hotfix/**'
      - 'test/**'
    paths:
      - 'dashboard/**'
      - 'cline-setup/**'
      - 'cline-ai/**'
      - '.github/workflows/deploy-dashboard.yml'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: false
        default: 'auto'
        type: choice
        options:
          - auto
          - production
          - staging

env:
  AWS_REGION: ap-southeast-1
  ECR_REPOSITORY: vibe-dashboard
  ECR_CODING_LAB: vibe-coding-lab
  ECS_CLUSTER: vibe-cluster
  ECS_SERVICE: vibe-dashboard
  CONTAINER_NAME: vibe-dashboard

jobs:
  build:
    name: Build Images
    runs-on: ubuntu-latest
    outputs:
      dashboard_image: ${{ steps.build-dashboard.outputs.image }}
      environment: ${{ steps.set-env.outputs.environment }}
      environment_name: ${{ steps.set-env.outputs.environment_name }}
      ecs_service: ${{ steps.set-env.outputs.ecs_service }}
      task_family: ${{ steps.set-env.outputs.task_family }}
      tg_name: ${{ steps.set-env.outputs.tg_name }}
      task_cpu: ${{ steps.set-env.outputs.task_cpu }}
      task_memory: ${{ steps.set-env.outputs.task_memory }}
      is_feature_branch: ${{ steps.set-env.outputs.is_feature_branch }}
      branch_slug: ${{ steps.set-env.outputs.branch_slug }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Set environment variables
        id: set-env
        run: |
          BRANCH="${{ github.ref_name }}"

          # Create a slug from branch name (lowercase, replace special chars, truncate)
          # AWS target group names max 32 chars: "vibe-test-" (10) + slug (16) + "-tg" (3) = 29
          BRANCH_SLUG=$(echo "$BRANCH" | sed 's|/|-|g' | sed 's|[^a-zA-Z0-9-]||g' | tr '[:upper:]' '[:lower:]' | cut -c1-16)
          echo "branch_slug=$BRANCH_SLUG" >> $GITHUB_OUTPUT

          # Determine environment type
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ "${{ inputs.environment }}" != "auto" ]; then
            # Manual dispatch with explicit environment
            if [ "${{ inputs.environment }}" == "production" ]; then
              ENVIRONMENT="production"
              ENVIRONMENT_NAME="production"
            else
              ENVIRONMENT="staging"
              ENVIRONMENT_NAME="staging"
            fi
            IS_FEATURE="false"
          elif [ "$BRANCH" == "main" ]; then
            ENVIRONMENT="production"
            ENVIRONMENT_NAME="production"
            IS_FEATURE="false"
          elif [ "$BRANCH" == "dev" ]; then
            ENVIRONMENT="staging"
            ENVIRONMENT_NAME="staging"
            IS_FEATURE="false"
          else
            # Feature/test branch - gets its own environment
            ENVIRONMENT="test"
            ENVIRONMENT_NAME="test-$BRANCH_SLUG"
            IS_FEATURE="true"
          fi

          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "environment_name=$ENVIRONMENT_NAME" >> $GITHUB_OUTPUT
          echo "is_feature_branch=$IS_FEATURE" >> $GITHUB_OUTPUT

          # Set resource names and sizing based on environment
          if [ "$ENVIRONMENT" == "production" ]; then
            echo "ecs_service=vibe-dashboard-service" >> $GITHUB_OUTPUT
            echo "task_family=vibe-dashboard" >> $GITHUB_OUTPUT
            echo "tg_name=vibe-dashboard-tg" >> $GITHUB_OUTPUT
            echo "task_cpu=512" >> $GITHUB_OUTPUT
            echo "task_memory=1024" >> $GITHUB_OUTPUT
          elif [ "$ENVIRONMENT" == "staging" ]; then
            echo "ecs_service=vibe-dashboard-staging" >> $GITHUB_OUTPUT
            echo "task_family=vibe-dashboard-staging" >> $GITHUB_OUTPUT
            echo "tg_name=vibe-dashboard-staging-tg" >> $GITHUB_OUTPUT
            echo "task_cpu=256" >> $GITHUB_OUTPUT
            echo "task_memory=512" >> $GITHUB_OUTPUT
          else
            # Feature branch - minimal resources
            echo "ecs_service=vibe-test-$BRANCH_SLUG" >> $GITHUB_OUTPUT
            echo "task_family=vibe-test-$BRANCH_SLUG" >> $GITHUB_OUTPUT
            echo "tg_name=vibe-test-$BRANCH_SLUG-tg" >> $GITHUB_OUTPUT
            echo "task_cpu=256" >> $GITHUB_OUTPUT
            echo "task_memory=512" >> $GITHUB_OUTPUT
          fi

          echo "Deploying branch '$BRANCH' as environment: $ENVIRONMENT_NAME"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create ECR repositories and ECS cluster if not exist
        run: |
          aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} 2>/dev/null || \
            aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}
          aws ecr describe-repositories --repository-names ${{ env.ECR_CODING_LAB }} 2>/dev/null || \
            aws ecr create-repository --repository-name ${{ env.ECR_CODING_LAB }}
          aws ecs describe-clusters --clusters ${{ env.ECS_CLUSTER }} --query 'clusters[0].status' --output text 2>/dev/null | grep -q ACTIVE || \
            aws ecs create-cluster --cluster-name ${{ env.ECS_CLUSTER }}

      - name: Build and push Dashboard image
        id: build-dashboard
        uses: docker/build-push-action@v5
        with:
          context: ./dashboard
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:latest
          build-args: |
            BUILD_SHA=${{ github.sha }}
          # Disable cache to ensure fresh builds with latest code
          no-cache: true

      - name: Check if coding labs changed
        id: changes
        run: |
          # Check if Continue setup changed
          if git diff --name-only HEAD~1 HEAD | grep -q "^cline-setup/"; then
            echo "continue_changed=true" >> $GITHUB_OUTPUT
          else
            echo "continue_changed=false" >> $GITHUB_OUTPUT
          fi

          # Check if Cline setup changed
          if git diff --name-only HEAD~1 HEAD | grep -q "^cline-ai/"; then
            echo "cline_changed=true" >> $GITHUB_OUTPUT
          else
            echo "cline_changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Build and push Continue image
        if: steps.changes.outputs.continue_changed == 'true' || github.event_name == 'workflow_dispatch'
        uses: docker/build-push-action@v5
        with:
          context: ./cline-setup
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_CODING_LAB }}:continue
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_CODING_LAB }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push Cline image
        if: steps.changes.outputs.cline_changed == 'true' || github.event_name == 'workflow_dispatch'
        uses: docker/build-push-action@v5
        with:
          context: ./cline-ai
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_CODING_LAB }}:cline
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy to ECS
    runs-on: ubuntu-latest
    needs: build

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get infrastructure info
        id: infra
        run: |
          # Get VPC
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=vibe-vpc" --query 'Vpcs[0].VpcId' --output text 2>/dev/null)
          if [ "$VPC_ID" == "None" ] || [ -z "$VPC_ID" ]; then
            VPC_ID=$(aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --query 'Vpcs[0].VpcId' --output text)
          fi
          echo "vpc_id=$VPC_ID" >> $GITHUB_OUTPUT

          SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[*].SubnetId' --output text | tr '\t' ',')
          echo "subnet_ids=$SUBNET_IDS" >> $GITHUB_OUTPUT

          # Get existing security groups
          ECS_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-ecs-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          echo "ecs_sg_id=$ECS_SG_ID" >> $GITHUB_OUTPUT

          # Get target group for this environment
          TG_NAME="${{ needs.build.outputs.tg_name }}"
          TG_ARN=$(aws elbv2 describe-target-groups --names $TG_NAME --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "")
          echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT
          echo "tg_name=$TG_NAME" >> $GITHUB_OUTPUT

          # Get EFS
          EFS_ID=$(aws efs describe-file-systems --creation-token vibe-dashboard-efs --query "FileSystems[0].FileSystemId" --output text 2>/dev/null || echo "")
          echo "efs_id=$EFS_ID" >> $GITHUB_OUTPUT

          AP_ID=$(aws efs describe-access-points --file-system-id $EFS_ID --query "AccessPoints[0].AccessPointId" --output text 2>/dev/null || echo "")
          echo "ap_id=$AP_ID" >> $GITHUB_OUTPUT

          # Check if first-time setup needed (core infrastructure)
          if [ -z "$ECS_SG_ID" ] || [ "$ECS_SG_ID" == "None" ] || [ -z "$EFS_ID" ] || [ "$EFS_ID" == "None" ] || [ -z "$AP_ID" ] || [ "$AP_ID" == "None" ]; then
            echo "needs_setup=true" >> $GITHUB_OUTPUT
          else
            echo "needs_setup=false" >> $GITHUB_OUTPUT
          fi

          # Check if this specific environment's target group exists
          if [ -z "$TG_ARN" ] || [ "$TG_ARN" == "None" ]; then
            echo "needs_tg_setup=true" >> $GITHUB_OUTPUT
          else
            echo "needs_tg_setup=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout for first-time setup
        if: steps.infra.outputs.needs_setup == 'true'
        uses: actions/checkout@v4

      - name: First-time infrastructure setup
        if: steps.infra.outputs.needs_setup == 'true'
        id: setup
        run: |
          VPC_ID="${{ steps.infra.outputs.vpc_id }}"
          SUBNET_IDS="${{ steps.infra.outputs.subnet_ids }}"

          # Create ALB security group
          ALB_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-alb-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          if [ "$ALB_SG_ID" == "None" ] || [ -z "$ALB_SG_ID" ]; then
            ALB_SG_ID=$(aws ec2 create-security-group --group-name vibe-dashboard-alb-sg --description "Vibe Dashboard ALB" --vpc-id $VPC_ID --query 'GroupId' --output text)
            aws ec2 authorize-security-group-ingress --group-id $ALB_SG_ID --protocol tcp --port 80 --cidr 0.0.0.0/0
            aws ec2 authorize-security-group-ingress --group-id $ALB_SG_ID --protocol tcp --port 443 --cidr 0.0.0.0/0
          fi
          echo "alb_sg_id=$ALB_SG_ID" >> $GITHUB_OUTPUT

          # Create ECS security group
          ECS_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-ecs-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          if [ "$ECS_SG_ID" == "None" ] || [ -z "$ECS_SG_ID" ]; then
            ECS_SG_ID=$(aws ec2 create-security-group --group-name vibe-dashboard-ecs-sg --description "Vibe Dashboard ECS" --vpc-id $VPC_ID --query 'GroupId' --output text)
            aws ec2 authorize-security-group-ingress --group-id $ECS_SG_ID --protocol tcp --port 3001 --source-group $ALB_SG_ID
          fi
          echo "ecs_sg_id=$ECS_SG_ID" >> $GITHUB_OUTPUT

          # Create EFS security group
          EFS_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-efs-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          if [ "$EFS_SG_ID" == "None" ] || [ -z "$EFS_SG_ID" ]; then
            EFS_SG_ID=$(aws ec2 create-security-group --group-name vibe-dashboard-efs-sg --description "Vibe Dashboard EFS" --vpc-id $VPC_ID --query 'GroupId' --output text)
            aws ec2 authorize-security-group-ingress --group-id $EFS_SG_ID --protocol tcp --port 2049 --source-group $ECS_SG_ID
          fi

          # Create ALB
          ALB_ARN=$(aws elbv2 describe-load-balancers --names vibe-dashboard-alb --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "None")
          if [ "$ALB_ARN" == "None" ]; then
            SUBNET_LIST=$(echo $SUBNET_IDS | tr ',' ' ')
            ALB_ARN=$(aws elbv2 create-load-balancer --name vibe-dashboard-alb --subnets $SUBNET_LIST --security-groups $ALB_SG_ID --scheme internet-facing --type application --query 'LoadBalancers[0].LoadBalancerArn' --output text)
          fi

          ALB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query 'LoadBalancers[0].DNSName' --output text)
          echo "alb_dns=$ALB_DNS" >> $GITHUB_OUTPUT

          # Create default target group (for production)
          TG_ARN=$(aws elbv2 describe-target-groups --names vibe-dashboard-tg --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "None")
          if [ "$TG_ARN" == "None" ]; then
            TG_ARN=$(aws elbv2 create-target-group --name vibe-dashboard-tg --protocol HTTP --port 3001 --vpc-id $VPC_ID --target-type ip --health-check-path /api/health --query 'TargetGroups[0].TargetGroupArn' --output text)
          fi
          echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT

          # Create listener
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn $ALB_ARN --query 'Listeners[?Port==`80`].ListenerArn' --output text 2>/dev/null)
          if [ -z "$LISTENER_ARN" ] || [ "$LISTENER_ARN" == "None" ]; then
            aws elbv2 create-listener --load-balancer-arn $ALB_ARN --protocol HTTP --port 80 --default-actions Type=forward,TargetGroupArn=$TG_ARN
          fi

          # Create EFS
          EFS_ID=$(aws efs describe-file-systems --creation-token vibe-dashboard-efs --query "FileSystems[0].FileSystemId" --output text 2>/dev/null || echo "None")
          if [ -z "$EFS_ID" ] || [ "$EFS_ID" == "None" ]; then
            EFS_ID=$(aws efs create-file-system --creation-token vibe-dashboard-efs --performance-mode generalPurpose --encrypted --query 'FileSystemId' --output text)
            echo "Waiting for EFS $EFS_ID to be available..."
            while true; do
              STATUS=$(aws efs describe-file-systems --file-system-id $EFS_ID --query 'FileSystems[0].LifeCycleState' --output text)
              if [ "$STATUS" == "available" ]; then
                echo "EFS is available"
                break
              fi
              echo "EFS status: $STATUS, waiting..."
              sleep 5
            done
          fi
          echo "efs_id=$EFS_ID" >> $GITHUB_OUTPUT

          # Create mount targets
          for SUBNET in $(echo $SUBNET_IDS | tr ',' ' '); do
            aws efs create-mount-target --file-system-id $EFS_ID --subnet-id $SUBNET --security-groups $EFS_SG_ID 2>/dev/null || true
          done

          # Create access point
          AP_ID=$(aws efs describe-access-points --file-system-id $EFS_ID --query "AccessPoints[0].AccessPointId" --output text 2>/dev/null)
          if [ -z "$AP_ID" ] || [ "$AP_ID" == "None" ]; then
            AP_ID=$(aws efs create-access-point --file-system-id $EFS_ID --posix-user Uid=1000,Gid=1000 --root-directory "Path=/dashboard-data,CreationInfo={OwnerUid=1000,OwnerGid=1000,Permissions=755}" --query 'AccessPointId' --output text)
          fi
          echo "ap_id=$AP_ID" >> $GITHUB_OUTPUT

          # Create IAM roles
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

          aws iam get-role --role-name ecsTaskRole 2>/dev/null || {
            aws iam create-role --role-name ecsTaskRole --assume-role-policy-document '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"ecs-tasks.amazonaws.com"},"Action":"sts:AssumeRole"}]}'
          }

          aws iam put-role-policy --role-name ecsTaskRole --policy-name efs-access --policy-document "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":[\"elasticfilesystem:ClientMount\",\"elasticfilesystem:ClientWrite\",\"elasticfilesystem:ClientRootAccess\"],\"Resource\":\"arn:aws:elasticfilesystem:${{ env.AWS_REGION }}:${AWS_ACCOUNT_ID}:file-system/${EFS_ID}\"}]}"

      - name: Setup environment-specific ALB and target group
        id: env-setup
        run: |
          VPC_ID="${{ steps.infra.outputs.vpc_id }}"
          SUBNET_IDS="${{ steps.infra.outputs.subnet_ids }}"
          ENVIRONMENT="${{ needs.build.outputs.environment }}"
          TG_NAME="${{ needs.build.outputs.tg_name }}"
          BRANCH_SLUG="${{ needs.build.outputs.branch_slug }}"

          # Get or create ALB security group
          ALB_SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=vibe-dashboard-alb-sg" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null)
          if [ "$ALB_SG_ID" == "None" ] || [ -z "$ALB_SG_ID" ]; then
            ALB_SG_ID=$(aws ec2 create-security-group --group-name vibe-dashboard-alb-sg --description "Vibe Dashboard ALB" --vpc-id $VPC_ID --query 'GroupId' --output text)
            aws ec2 authorize-security-group-ingress --group-id $ALB_SG_ID --protocol tcp --port 80 --cidr 0.0.0.0/0
            aws ec2 authorize-security-group-ingress --group-id $ALB_SG_ID --protocol tcp --port 443 --cidr 0.0.0.0/0
          fi

          # Determine ALB name based on environment
          if [ "$ENVIRONMENT" == "production" ]; then
            ALB_NAME="vibe-dashboard-alb"
          elif [ "$ENVIRONMENT" == "staging" ]; then
            ALB_NAME="vibe-dashboard-staging-alb"
          else
            # Feature branch gets its own ALB
            ALB_NAME="vibe-test-${BRANCH_SLUG}-alb"
            # Truncate to 32 chars max for ALB name
            ALB_NAME=$(echo "$ALB_NAME" | cut -c1-32)
          fi
          echo "alb_name=$ALB_NAME" >> $GITHUB_OUTPUT

          # Check if ALB exists, create if not
          ALB_ARN=$(aws elbv2 describe-load-balancers --names $ALB_NAME --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "None")

          if [ "$ALB_ARN" == "None" ] || [ -z "$ALB_ARN" ]; then
            echo "Creating ALB: $ALB_NAME"
            SUBNET_LIST=$(echo $SUBNET_IDS | tr ',' ' ')
            ALB_ARN=$(aws elbv2 create-load-balancer \
              --name $ALB_NAME \
              --subnets $SUBNET_LIST \
              --security-groups $ALB_SG_ID \
              --scheme internet-facing \
              --type application \
              --query 'LoadBalancers[0].LoadBalancerArn' --output text)

            echo "Waiting for ALB to be active..."
            aws elbv2 wait load-balancer-available --load-balancer-arns $ALB_ARN
          fi
          echo "alb_arn=$ALB_ARN" >> $GITHUB_OUTPUT

          # Get ALB DNS
          ALB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query 'LoadBalancers[0].DNSName' --output text)
          echo "alb_dns=$ALB_DNS" >> $GITHUB_OUTPUT

          # Check if target group exists
          TG_ARN=$(aws elbv2 describe-target-groups --names $TG_NAME --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "None")

          if [ "$TG_ARN" != "None" ] && [ -n "$TG_ARN" ]; then
            # Target group exists - check if it's associated with a different ALB
            # We need to delete any old listener rules using this TG before we can use it with new ALB
            echo "Target group exists: $TG_ARN"
            echo "Checking for old associations..."

            # Find all load balancers and check their listeners for rules using this TG
            OLD_ALBS=$(aws elbv2 describe-load-balancers --query 'LoadBalancers[*].LoadBalancerArn' --output text 2>/dev/null || echo "")
            for OLD_ALB in $OLD_ALBS; do
              if [ "$OLD_ALB" != "$ALB_ARN" ]; then
                OLD_LISTENERS=$(aws elbv2 describe-listeners --load-balancer-arn $OLD_ALB --query 'Listeners[*].ListenerArn' --output text 2>/dev/null || echo "")
                for OLD_LISTENER in $OLD_LISTENERS; do
                  # Find rules using our target group
                  RULE_ARNS=$(aws elbv2 describe-rules --listener-arn $OLD_LISTENER --query "Rules[?Actions[?TargetGroupArn=='$TG_ARN']].RuleArn" --output text 2>/dev/null || echo "")
                  for RULE_ARN in $RULE_ARNS; do
                    if [ -n "$RULE_ARN" ] && [ "$RULE_ARN" != "None" ]; then
                      # Check if it's the default rule (can't delete those)
                      IS_DEFAULT=$(aws elbv2 describe-rules --rule-arns $RULE_ARN --query 'Rules[0].IsDefault' --output text 2>/dev/null || echo "false")
                      if [ "$IS_DEFAULT" != "true" ]; then
                        echo "Deleting old listener rule: $RULE_ARN"
                        aws elbv2 delete-rule --rule-arn $RULE_ARN 2>/dev/null || true
                      fi
                    fi
                  done
                done
              fi
            done

            # Delete the old target group and create fresh
            echo "Deleting old target group to avoid association conflicts..."
            aws elbv2 delete-target-group --target-group-arn $TG_ARN 2>/dev/null || true
            sleep 2
          fi

          # Create fresh target group with better health check settings
          echo "Creating target group: $TG_NAME"
          TG_ARN=$(aws elbv2 create-target-group \
            --name $TG_NAME \
            --protocol HTTP --port 3001 \
            --vpc-id $VPC_ID --target-type ip \
            --health-check-path /api/health \
            --health-check-interval-seconds 30 \
            --health-check-timeout-seconds 10 \
            --healthy-threshold-count 2 \
            --unhealthy-threshold-count 3 \
            --query 'TargetGroups[0].TargetGroupArn' --output text)
          echo "tg_arn=$TG_ARN" >> $GITHUB_OUTPUT

          # Check if listener exists, create or update it
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn $ALB_ARN --query 'Listeners[?Port==`80`].ListenerArn' --output text 2>/dev/null || echo "")

          if [ -z "$LISTENER_ARN" ] || [ "$LISTENER_ARN" == "None" ]; then
            echo "Creating listener for ALB"
            LISTENER_ARN=$(aws elbv2 create-listener \
              --load-balancer-arn $ALB_ARN \
              --protocol HTTP --port 80 \
              --default-actions Type=forward,TargetGroupArn=$TG_ARN \
              --query 'Listeners[0].ListenerArn' --output text)
          else
            echo "Updating listener default action to new target group"
            aws elbv2 modify-listener \
              --listener-arn $LISTENER_ARN \
              --default-actions Type=forward,TargetGroupArn=$TG_ARN
          fi
          echo "listener_arn=$LISTENER_ARN" >> $GITHUB_OUTPUT

          echo ""
          echo "========================================"
          echo "  ALB Setup Complete"
          echo "  ALB Name: $ALB_NAME"
          echo "  ALB DNS:  $ALB_DNS"
          echo "========================================"

      - name: Get ECR registry
        id: ecr
        run: |
          REGISTRY=$(aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --query 'repositories[0].repositoryUri' --output text | sed 's|/.*||')
          echo "registry=$REGISTRY" >> $GITHUB_OUTPUT

      - name: Register task definition
        id: task-def
        run: |
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REGISTRY="${{ steps.ecr.outputs.registry }}"
          ENVIRONMENT="${{ needs.build.outputs.environment }}"
          ENVIRONMENT_NAME="${{ needs.build.outputs.environment_name }}"
          TASK_FAMILY="${{ needs.build.outputs.task_family }}"
          TASK_CPU="${{ needs.build.outputs.task_cpu }}"
          TASK_MEMORY="${{ needs.build.outputs.task_memory }}"
          BRANCH_SLUG="${{ needs.build.outputs.branch_slug }}"

          # Use setup outputs if first-time, otherwise use infra outputs
          if [ "${{ steps.infra.outputs.needs_setup }}" == "true" ]; then
            EFS_ID="${{ steps.setup.outputs.efs_id }}"
            AP_ID="${{ steps.setup.outputs.ap_id }}"
          else
            EFS_ID="${{ steps.infra.outputs.efs_id }}"
            AP_ID="${{ steps.infra.outputs.ap_id }}"
          fi

          cat > task-def.json << EOF
          {
            "family": "${TASK_FAMILY}",
            "networkMode": "awsvpc",
            "requiresCompatibilities": ["FARGATE"],
            "cpu": "${TASK_CPU}",
            "memory": "${TASK_MEMORY}",
            "executionRoleArn": "arn:aws:iam::${AWS_ACCOUNT_ID}:role/ecsTaskExecutionRole",
            "taskRoleArn": "arn:aws:iam::${AWS_ACCOUNT_ID}:role/ecsTaskRole",
            "containerDefinitions": [{
              "name": "${{ env.CONTAINER_NAME }}",
              "image": "${ECR_REGISTRY}/${{ env.ECR_REPOSITORY }}:${{ github.sha }}",
              "essential": true,
              "portMappings": [{"containerPort": 3001, "protocol": "tcp"}],
              "environment": [
                {"name": "NODE_ENV", "value": "production"},
                {"name": "ENVIRONMENT", "value": "${ENVIRONMENT}"},
                {"name": "ENVIRONMENT_NAME", "value": "${ENVIRONMENT_NAME}"},
                {"name": "PORT", "value": "3001"},
                {"name": "DATA_DIR", "value": "/mnt/efs/data"}
              ],
              "mountPoints": [{"sourceVolume": "efs-data", "containerPath": "/mnt/efs/data", "readOnly": false}],
              "logConfiguration": {
                "logDriver": "awslogs",
                "options": {
                  "awslogs-group": "/ecs/vibe-dashboard",
                  "awslogs-region": "${{ env.AWS_REGION }}",
                  "awslogs-stream-prefix": "ecs",
                  "awslogs-create-group": "true"
                }
              },
              "healthCheck": {
                "command": ["CMD-SHELL", "wget -q --spider http://localhost:3001/api/health || exit 1"],
                "interval": 30, "timeout": 5, "retries": 3, "startPeriod": 60
              }
            }],
            "volumes": [{
              "name": "efs-data",
              "efsVolumeConfiguration": {
                "fileSystemId": "${EFS_ID}",
                "transitEncryption": "ENABLED",
                "authorizationConfig": {"accessPointId": "${AP_ID}", "iam": "ENABLED"}
              }
            }]
          }
          EOF

          TASK_DEF_ARN=$(aws ecs register-task-definition --cli-input-json file://task-def.json --query 'taskDefinition.taskDefinitionArn' --output text)
          echo "task_def_arn=$TASK_DEF_ARN" >> $GITHUB_OUTPUT

      - name: Deploy to ECS (update or create service)
        run: |
          ENVIRONMENT="${{ needs.build.outputs.environment }}"
          ECS_SERVICE_NAME="${{ needs.build.outputs.ecs_service }}"
          TG_ARN="${{ steps.env-setup.outputs.tg_arn }}"

          # Get security group
          if [ "${{ steps.infra.outputs.needs_setup }}" == "true" ]; then
            ECS_SG_ID="${{ steps.setup.outputs.ecs_sg_id }}"
          else
            ECS_SG_ID="${{ steps.infra.outputs.ecs_sg_id }}"
          fi

          SUBNET_IDS="${{ steps.infra.outputs.subnet_ids }}"

          echo "Deploying environment: ${{ needs.build.outputs.environment_name }}"
          echo "Service: $ECS_SERVICE_NAME"
          echo "Target Group: $TG_ARN"

          # Check if service exists and its status
          SERVICE_STATUS=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services $ECS_SERVICE_NAME --query 'services[0].status' --output text 2>/dev/null || echo "MISSING")

          # If service exists, check if its target group matches
          NEEDS_RECREATE="false"
          if [ "$SERVICE_STATUS" == "ACTIVE" ]; then
            CURRENT_TG=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services $ECS_SERVICE_NAME --query 'services[0].loadBalancers[0].targetGroupArn' --output text 2>/dev/null || echo "")
            if [ "$CURRENT_TG" != "$TG_ARN" ]; then
              echo "Target group changed from $CURRENT_TG to $TG_ARN"
              echo "Service must be recreated (can't change load balancer config on existing service)"
              NEEDS_RECREATE="true"
            fi
          fi

          if [ "$SERVICE_STATUS" == "ACTIVE" ] && [ "$NEEDS_RECREATE" == "false" ]; then
            echo "Updating existing service..."
            aws ecs update-service \
              --cluster ${{ env.ECS_CLUSTER }} \
              --service $ECS_SERVICE_NAME \
              --task-definition ${{ steps.task-def.outputs.task_def_arn }} \
              --force-new-deployment
          elif [ "$SERVICE_STATUS" == "ACTIVE" ] && [ "$NEEDS_RECREATE" == "true" ]; then
            echo "Deleting service to recreate with new target group..."
            aws ecs update-service --cluster ${{ env.ECS_CLUSTER }} --service $ECS_SERVICE_NAME --desired-count 0 2>/dev/null || true
            aws ecs delete-service --cluster ${{ env.ECS_CLUSTER }} --service $ECS_SERVICE_NAME --force
            echo "Waiting for service to be fully deleted..."

            # Wait for service to finish draining and become inactive
            for i in {1..30}; do
              STATUS=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services $ECS_SERVICE_NAME --query 'services[0].status' --output text 2>/dev/null || echo "MISSING")
              RUNNING=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services $ECS_SERVICE_NAME --query 'services[0].runningCount' --output text 2>/dev/null || echo "0")
              echo "Service status: $STATUS, running tasks: $RUNNING"
              if [ "$STATUS" == "INACTIVE" ] || [ "$STATUS" == "MISSING" ] || [ "$STATUS" == "None" ]; then
                echo "Service is now inactive"
                break
              fi
              if [ "$STATUS" == "DRAINING" ] && [ "$RUNNING" == "0" ]; then
                echo "Service drained, waiting a bit more for cleanup..."
                sleep 5
                break
              fi
              echo "Waiting for service to drain... ($i/30)"
              sleep 10
            done

            echo "Creating new service with new target group..."
            aws ecs create-service \
              --cluster ${{ env.ECS_CLUSTER }} \
              --service-name $ECS_SERVICE_NAME \
              --task-definition ${{ steps.task-def.outputs.task_def_arn }} \
              --desired-count 1 \
              --launch-type FARGATE \
              --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],securityGroups=[$ECS_SG_ID],assignPublicIp=ENABLED}" \
              --load-balancers "targetGroupArn=$TG_ARN,containerName=${{ env.CONTAINER_NAME }},containerPort=3001" \
              --deployment-configuration "minimumHealthyPercent=0,maximumPercent=200" \
              --health-check-grace-period-seconds 120
          elif [ "$SERVICE_STATUS" == "DRAINING" ]; then
            echo "Service is draining, waiting for it to complete..."
            for i in {1..30}; do
              STATUS=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services $ECS_SERVICE_NAME --query 'services[0].status' --output text 2>/dev/null || echo "MISSING")
              RUNNING=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services $ECS_SERVICE_NAME --query 'services[0].runningCount' --output text 2>/dev/null || echo "0")
              echo "Service status: $STATUS, running tasks: $RUNNING"
              if [ "$STATUS" == "INACTIVE" ] || [ "$STATUS" == "MISSING" ] || [ "$STATUS" == "None" ]; then
                echo "Service is now inactive"
                break
              fi
              if [ "$STATUS" == "DRAINING" ] && [ "$RUNNING" == "0" ]; then
                echo "Service drained, waiting a bit more for cleanup..."
                sleep 5
                break
              fi
              echo "Waiting for service to drain... ($i/30)"
              sleep 10
            done

            echo "Creating new service..."
            aws ecs create-service \
              --cluster ${{ env.ECS_CLUSTER }} \
              --service-name $ECS_SERVICE_NAME \
              --task-definition ${{ steps.task-def.outputs.task_def_arn }} \
              --desired-count 1 \
              --launch-type FARGATE \
              --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],securityGroups=[$ECS_SG_ID],assignPublicIp=ENABLED}" \
              --load-balancers "targetGroupArn=$TG_ARN,containerName=${{ env.CONTAINER_NAME }},containerPort=3001" \
              --deployment-configuration "minimumHealthyPercent=0,maximumPercent=200" \
              --health-check-grace-period-seconds 120
          else
            echo "Creating new service..."
            # Delete inactive service if exists
            aws ecs delete-service --cluster ${{ env.ECS_CLUSTER }} --service $ECS_SERVICE_NAME --force 2>/dev/null || true
            sleep 5

            aws ecs create-service \
              --cluster ${{ env.ECS_CLUSTER }} \
              --service-name $ECS_SERVICE_NAME \
              --task-definition ${{ steps.task-def.outputs.task_def_arn }} \
              --desired-count 1 \
              --launch-type FARGATE \
              --network-configuration "awsvpcConfiguration={subnets=[$SUBNET_IDS],securityGroups=[$ECS_SG_ID],assignPublicIp=ENABLED}" \
              --load-balancers "targetGroupArn=$TG_ARN,containerName=${{ env.CONTAINER_NAME }},containerPort=3001" \
              --deployment-configuration "minimumHealthyPercent=0,maximumPercent=200" \
              --health-check-grace-period-seconds 120
          fi

      - name: Output URLs
        run: |
          ENVIRONMENT="${{ needs.build.outputs.environment }}"
          ENVIRONMENT_NAME="${{ needs.build.outputs.environment_name }}"
          ECS_SERVICE_NAME="${{ needs.build.outputs.ecs_service }}"
          BRANCH_SLUG="${{ needs.build.outputs.branch_slug }}"
          ALB_DNS="${{ steps.env-setup.outputs.alb_dns }}"
          ALB_NAME="${{ steps.env-setup.outputs.alb_name }}"

          echo ""
          echo "========================================"
          echo "  DEPLOYMENT COMPLETE!"
          echo "========================================"
          echo ""
          echo "  Environment: $ENVIRONMENT_NAME"
          echo "  Service: $ECS_SERVICE_NAME"
          echo "  Branch: ${{ github.ref_name }}"
          echo "  ALB: $ALB_NAME"
          echo ""
          echo "  URLs (direct access - no headers needed):"
          echo "    Dashboard:    http://$ALB_DNS"
          echo "    Admin Login:  http://$ALB_DNS/#/login"
          echo "    Admin Panel:  http://$ALB_DNS/#/admin"
          echo "    Participant:  http://$ALB_DNS/#/enter"
          echo "    Health Check: http://$ALB_DNS/api/health"
          echo "    Version:      http://$ALB_DNS/api/version"
          echo ""
          if [ "$ENVIRONMENT" == "test" ]; then
            echo "  Note: This is a feature branch deployment with its own ALB."
            echo "  Main branch (production) remains unaffected at vibe-dashboard-alb"
          fi
          echo "========================================"
